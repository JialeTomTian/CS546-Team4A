{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TORCH_DISTRIBUTED_DEBUG'] = 'INFO'\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/scratch/.cache\"\n",
    "os.environ['HF_DATASETS_CACHE'] = \"/scratch/.cache\"\n",
    "os.environ['HF_HOME'] =  \"/scratch/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "\n",
    "# version = \n",
    "model = \"bigcode/octocoder\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt_template = '''Question: You are an expert programmer. Your tasl is to refactor the given code to improve readability, maintainability, and performance without changing functionality. \n",
    "\n",
    "The code to refactor is provided between `<code>` and `</code>` tags.\n",
    "\n",
    "Refactor the following code:\n",
    "<code>{input_code}</code>\n",
    "\n",
    "Please return the refactored code without any explanation.\n",
    "Answer:'''\n",
    "\n",
    "\n",
    "def run_llm(prompt, max_new_tokens=512):\n",
    "    response = pipeline(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        temperature=0.1,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        return_full_text=False,\n",
    "        )\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "\n",
    "\n",
    "def get_clean_code(response):\n",
    "    pattern = r'```(\\w+)?\\n(.*?)\\n```'\n",
    "    code_match = re.search(pattern, response, re.DOTALL)\n",
    "    code = code_match.group(2).strip() if code_match else response\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on HumanEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_path = '../dataset/HumanEvalPlusOrig.jsonl'\n",
    "output_path = f'../results/octocoder/HumanEvalRefactored.jsonl'\n",
    "\n",
    "\n",
    "\n",
    "humaneval = []\n",
    "with open(data_path, 'r') as fp:\n",
    "    for item in jsonlines.Reader(fp):\n",
    "        humaneval.append(item)\n",
    "print(len(humaneval))\n",
    "\n",
    "\n",
    "for sample in tqdm(humaneval):\n",
    "    prompt = prompt_template.format(input_code = sample['prompt'])\n",
    "    response = run_llm(prompt=prompt)\n",
    "    # print(response)\n",
    "    refactored_code = get_clean_code(response)\n",
    "    if refactored_code is  None:\n",
    "        print(\"Code Parsing ERROR: \", response)\n",
    "        refactored_code = '' \n",
    "    sample['refactored_code'] = refactored_code\n",
    "\n",
    "import json\n",
    "with open(output_path,'w') as fp:\n",
    "    for sample in humaneval:\n",
    "        fp.write(json.dumps(sample) + '\\n')\n",
    "print('Output Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for sample in humaneval:\n",
    "    if len(sample['refactored_code']) == 0:\n",
    "        count += 1\n",
    "    else:\n",
    "        print(sample['refactored_code'], '\\n')\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on GuruSamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os \n",
    "\n",
    "data_folder = '../dataset/GuruSamples'\n",
    "output_folder = f'../results/octocoder/GuruSamples'\n",
    "\n",
    "for folder_name in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "        pattern = os.path.join(folder_path, '*_before.*')\n",
    "\n",
    "# iter  = 10\n",
    "    print(folder_name)\n",
    "    # if folder_name != 'typescript':\n",
    "    #     continue\n",
    "    for file_path in glob.glob(pattern):\n",
    "        filename = os.path.basename(file_path)\n",
    "        with open(file_path, 'r') as file:\n",
    "            code_content = file.read()\n",
    "        # print(filename)\n",
    "        \n",
    "        # print(output_filename)\n",
    "\n",
    "        # print('Input: ', code_content, '\\n')\n",
    "        prompt = prompt_template.format(input_code = code_content)\n",
    "\n",
    "        response = run_llm(prompt=prompt)\n",
    "        # print('LLM OUTPUT: ', response)\n",
    "        refactored_code = get_clean_code(response)\n",
    "        # print('CLEAN CODE: ', refactored_code)\n",
    "        if refactored_code is None:\n",
    "            refactored_code = ''\n",
    "            print('Parsing Error!, ', response)\n",
    "\n",
    "        # break\n",
    "\n",
    "        ouput_folder_path = os.path.join(output_folder, folder_name)\n",
    "        if not os.path.exists(ouput_folder_path):\n",
    "            os.mkdir(ouput_folder_path)\n",
    "        output_filename = filename.replace('_before', '_refactored')\n",
    "        with open(os.path.join(ouput_folder_path, output_filename), 'w') as output_file:\n",
    "            output_file.write(refactored_code)\n",
    "\n",
    "# parent_folder = os.path.dirname(output_folder)\n",
    "# print(parent_folder)\n",
    "# if not os.path.exists(parent_folder):\n",
    "#     os.mkdir(parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
